{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmOpti Workshop - XGboost\n",
    "\n",
    "Kernel `Python 3 (Data Science)` works well with this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "session = sagemaker.Session()\n",
    "s3bucket = session.default_bucket()\n",
    "s3prefix = \"emopti\"\n",
    "local_data_path = './data/emopti_data.csv'\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'train.csv'\n",
    "\n",
    "train_data_s3path = session.upload_data(bucket=s3bucket, path=f'data/xgb/{train_filename}', key_prefix=f'{s3prefix}/xgb/data')\n",
    "print(\"Train data uploaded to: \" + train_data_s3path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(f's3://{s3bucket}/{s3prefix}/xgb/data', content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This line automatically looks for the XGBoost image URI and builds an XGBoost container using the specified version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.3-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"verbosity\":\"1\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"\n",
    "}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "output_path = f's3://{s3bucket}/{s3prefix}/xgb-output/'\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb = sagemaker.estimator.Estimator(image_uri=xgb_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker_role,\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.c5.4xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb.fit({'train': train_input})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an endpoint for doing predictions with the trained model  \n",
    "The endpoint will take a few minutes to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "xgb_predictor = xgb.deploy(\n",
    "\tinitial_instance_count = 1,\n",
    "\tinstance_type = 'ml.m5.xlarge',\n",
    "\tserializer = CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/xgb/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/xgb/test.csv') as fd:\n",
    "    lines = fd.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = []\n",
    "for line in lines[1:]:\n",
    "    val = float(xgb_predictor.predict(line))\n",
    "    pred = 0\n",
    "    if val > 0.6:\n",
    "        pred = 1\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_test_labels = pd.read_csv('data/xgb/test_labels.csv', header=None)\n",
    "df_test_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test_labels, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "#labels = [f'True Neg\\n{cm[0][0]}', f'False Pos\\n{cm[0][1]}', f'False Neg\\n{cm[1][0]}', f'True Pos\\n{cm[1][1]}']\n",
    "#labels = np.asarray(labels).reshape(2,2)\n",
    "ax = sns.heatmap(cm, annot=True, fmt='', cmap='Blues')\n",
    "ax.set_xticklabels(['ADMIT', 'DISCHARGE'])\n",
    "ax.set_yticklabels(['ADMIT', 'DISCHARGE'])\n",
    "ax.set(ylabel = \"True Label\", xlabel = \"Predicted Label\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The predictor endpoint will run indefinitely, so delete the endpoint to stop any charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
